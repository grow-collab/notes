import pandas as pd

'''
分块读取⼤⽂件的主要⽬的是为了优化内存的使⽤和提⾼读取的效率。当处理⼤⽂件时，将整个⽂件⼀次性加
载到内存中可能会导致内存不⾜的问题，特别是在处理⾮常⼤的⽂件时。此外，直接⼀次性读取整个⽂件可能
会导致读取时间过⻓，影响程序的响应性能。
通过分块读取⼤⽂件，可以将⽂件分割成较⼩的块，逐块读取并处理。这种⽅式有以下好处：
1. 节省内存：只需要将⽂件的⼀部分加载到内存中，⽽不是加载整个⽂件，可以减少内存的消耗。
2. 提⾼读取速度：按块读取⽂件可以避免⼀次性读取整个⽂件的时间开销。因为⽂件操作往往是相对较慢
的，逐块读取可以将⽂件的读取时间分摊到多个较⼩的操作中，从⽽提⾼读取速度。
3. 更好的响应性能：如果⽂件读取过程涉及与⽤户交互或其他任务并发执⾏，分块读取可以使程序更加响应，减少等待时间。
分块读取⼤⽂件的具体实现可以使⽤⽂件流（File Stream）或者按⾏读取⽂件，根据具体需求和⽂件格式选择
合适的⽅式。
'''

# pd1 = pd.read_csv('./数据/bus.csv',encoding='gbk')
# print(pd1.head(10)) # 这种不是分块读取,

# 怎么才是分块读取
# chunksize=10,每一次读取十个数据
pd1 = pd.read_csv('./数据/bus.csv',encoding='gbk',chunksize=10)
print(pd1,type(pd1))
print(pd1.get_chunk())
print(pd1.get_chunk(20))

#iterator=True 意味着启⽤迭代器模式，这将返回⼀个迭代器对象⽽不是完整的DataFrame。
#在迭代器模式下，数据将按块读取，⽽不是⼀次性将整个DataFrame加载到内存中。
#每次调⽤ __next__() ⽅法时，将返回⼀个包含指定⾏数的DataFrame块。
#当到达数据的末尾时，__next__() ⽅法将引发 StopIteration 异常。
#使⽤ iterator=True 可以⽤于处理⼤型数据⽂件，以避免内存不⾜的问题。
#通过按块读取数据，可以减少内存使⽤并提⾼效率。
pd2 = pd.read_csv('./数据/bus.csv',encoding='gbk',iterator=True)
print(pd2,type(pd2))
print(pd2.__next__())